# Abstract
This project is intended to develop a real-time speech recognition system using deep learning methods to classify spoken words into predefined categories. The system is implemented with TensorFlow and Keras, Convolutional Neural Networks (CNNs) for feature extraction, and classification. The dataset contains audio samples of four specific commands: "Left," "Right," "Up," and "Down." It utilizes Mel-frequency spectrograms, which is a time-frequency representation of the audio signals, thus providing a very strong base for speech pattern recognition.

In order to increase this real dataset, techniques are addition of Gaussian noise, time stretch, pitch shift, and time shift. This will enable the model to generalize better against unseen audio variations.
